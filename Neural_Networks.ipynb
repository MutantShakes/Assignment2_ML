{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "train_features = pd.read_csv(\"./train_NN.csv\")\n",
    "train_labels = pd.read_csv(\"./train_labels_NN.csv\")\n",
    "test_features = pd.read_csv(\"test_NN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    88304\n",
      "0.0    88304\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_labels.head()\n",
    "label_frequencies = train_labels['0'].value_counts()\n",
    "print(label_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Custom RBF activation function\n",
    "def rbf_activation(x):\n",
    "    return tf.math.exp(-1.0 * tf.square(x))\n",
    "\n",
    "class SimpleNeuralNetwork:\n",
    "    def __init__(self, input_dim, hidden_units, output_dim):\n",
    "        self.model = self.build_model(input_dim, hidden_units, output_dim)\n",
    "\n",
    "    def build_model(self, input_dim, hidden_units, output_dim):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(hidden_units, input_dim=input_dim, activation='relu'))\n",
    "        model.add(Dense(hidden_units, activation='relu'))\n",
    "        model.add(Dense(output_dim, activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def train(self, X_train, y_train, epochs, batch_size, validation_data=None):\n",
    "        self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=validation_data)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        loss, accuracy = self.model.evaluate(X_test, y_test)\n",
    "        print(f'Test Loss: {loss:.4f}')\n",
    "        print(f'Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    def predict(self, X_data, threshold=0.5):\n",
    "        predictions_proba = self.model.predict(X_data)\n",
    "        predictions = (predictions_proba > threshold).astype(int)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "# Custom RBF activation function\n",
    "def rbf_activation(x):\n",
    "    return tf.math.exp(-1.0 * tf.square(x))\n",
    "\n",
    "class SimpleNeuralNetwork:\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def build_model(self, hp):\n",
    "        model = Sequential()\n",
    "\n",
    "        # Tune the number of hidden layers and units in each layer\n",
    "        for i in range(hp.Int('num_hidden_layers', min_value=1, max_value=3)):\n",
    "            model.add(Dense(units=hp.Int(f'units_{i}', min_value=8, max_value=128), \n",
    "                            activation=hp.Choice(f'activation_{i}', values=['relu', 'tanh']),\n",
    "                            input_dim=self.input_dim if i == 0 else None))\n",
    "\n",
    "        model.add(Dense(units=self.output_dim, activation='sigmoid'))\n",
    "\n",
    "        # Tune the learning rate\n",
    "        model.compile(\n",
    "            loss='binary_crossentropy',\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=hp.Choice('learning_rate', values=[1e-3, 1e-4, 1e-5])),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        return model\n",
    "\n",
    "    def tune_hyperparameters(self, X_train, y_train, epochs, batch_size, validation_data=None):\n",
    "        tuner = RandomSearch(\n",
    "            self.build_model,\n",
    "            objective='val_accuracy',\n",
    "            max_trials=10,  # Number of hyperparameter combinations to try\n",
    "            directory='keras_tuner_dir',  # Directory to store the results\n",
    "            project_name='simple_neural_network'\n",
    "        )\n",
    "\n",
    "        tuner.search(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=validation_data)\n",
    "        \n",
    "        # Get the best model and its hyperparameters\n",
    "        best_model = tuner.get_best_models(num_models=1)[0]\n",
    "        best_hyperparameters = tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values\n",
    "\n",
    "        self.model = best_model\n",
    "        return best_hyperparameters\n",
    "\n",
    "    def train(self, X_train, y_train, epochs, batch_size, validation_data=None):\n",
    "        self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=validation_data)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        loss, accuracy = self.model.evaluate(X_test, y_test)\n",
    "        print(f'Test Loss: {loss:.4f}')\n",
    "        print(f'Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    def predict(self, X_data, threshold=0.5):\n",
    "        predictions_proba = self.model.predict(X_data)\n",
    "        predictions = (predictions_proba > threshold).astype(int)\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_units = input_dim\n",
    "output_dim = 1\n",
    "\n",
    "# Instantiate the SimpleNeuralNetwork class\n",
    "# simple_nn = SimpleNeuralNetwork(input_dim, hidden_units, output_dim)\n",
    "simple_nn = SimpleNeuralNetwork(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_nn.tune_hyperparameters(X_train, y_train, epochs=30, batch_size=64, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_nn.tune_hyperparameters(train_features, train_labels, epochs=30, batch_size=64, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "simple_nn.train(X_train, y_train, epochs=30, batch_size=64, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "simple_nn.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_nn.train(train_features, train_labels, epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\suyash\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Custom RBF activation function\n",
    "def rbf_activation(x):\n",
    "    return tf.math.exp(-1.0 * tf.square(x))\n",
    "\n",
    "class SimpleNeuralNetwork:\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.model = None  # Initialize model attribute\n",
    "\n",
    "    def build_model(self, hp):\n",
    "        model = Sequential()\n",
    "\n",
    "        # Add the specified number of hidden layers with units and activations\n",
    "        for i in range(hp.get('num_hidden_layers')):\n",
    "            model.add(Dense(\n",
    "                units=hp.get(f'units_{i}'),\n",
    "                activation=hp.get(f'activation_{i}'),\n",
    "                input_dim=self.input_dim if i == 0 else None\n",
    "            ))\n",
    "\n",
    "        model.add(Dense(units=self.output_dim, activation='sigmoid'))\n",
    "\n",
    "        # Compile the model with the specified learning rate\n",
    "        model.compile(\n",
    "            loss='binary_crossentropy',\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=hp.get('learning_rate')),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        self.model = model  # Store the model in the attribute\n",
    "        return model\n",
    "\n",
    "    # Other methods remain unchanged\n",
    "    # def train(self, X_train, y_train, epochs, batch_size, validation_data=None):\n",
    "    #     class_weights = {0:8, 1:3}  # Adjust class weights based on your data distribution\n",
    "    #     self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=validation_data, class_weight=class_weights)\n",
    "    def train(self, X_train, y_train, epochs, batch_size, validation_data=None):\n",
    "        self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=validation_data)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        loss, accuracy = self.model.evaluate(X_test, y_test)\n",
    "        print(f'Test Loss: {loss:.4f}')\n",
    "        print(f'Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    def predict(self, X_data, threshold=0.5):\n",
    "        predictions_proba = self.model.predict(X_data)\n",
    "        predictions = (predictions_proba > threshold).astype(int)\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\suyash\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "hidden_units = input_dim\n",
    "output_dim = 1\n",
    "\n",
    "# Instantiate SimpleNeuralNetwork with input_dim and output_dim\n",
    "simple_nn = SimpleNeuralNetwork(input_dim, output_dim)\n",
    "\n",
    "# Get the hyperparameters dictionary\n",
    "hyperparameters = {'num_hidden_layers': 1,\n",
    "                   'units_0': 74,\n",
    "                   'activation_0': 'relu',\n",
    "                   'learning_rate': 0.0001,\n",
    "                   'units_1': 116,\n",
    "                   'activation_1': 'relu',\n",
    "                   'units_2': 118,\n",
    "                   'activation_2': 'tanh'}\n",
    "\n",
    "# Build the model using the provided hyperparameters\n",
    "model = simple_nn.build_model(hyperparameters)\n",
    "\n",
    "# Now, you can train, evaluate, and predict with this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "# Custom RBF activation function\n",
    "def rbf_activation(x):\n",
    "    return tf.math.exp(-1.0 * tf.square(x))\n",
    "\n",
    "class SimpleNeuralNetwork:\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.model = None  # Initialize model attribute\n",
    "\n",
    "    def build_model(self, hp):\n",
    "        model = Sequential()\n",
    "\n",
    "        # Add the specified number of hidden layers with units and activations\n",
    "        for i in range(hp.get('num_hidden_layers')):\n",
    "            model.add(Dense(\n",
    "                units=hp.get(f'units_{i}'),\n",
    "                activation=hp.get(f'activation_{i}'),\n",
    "                kernel_initializer=hp.get(f'kernel_initializer_{i}'),\n",
    "                kernel_regularizer=hp.get(f'kernel_regularizer_{i}'),\n",
    "                input_dim=self.input_dim if i == 0 else None\n",
    "            ))\n",
    "\n",
    "            if hp.get(f'batch_normalization_{i}'):\n",
    "                model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "            model.add(tf.keras.layers.Dropout(hp.get(f'dropout_{i}')))\n",
    "                    \n",
    "        model.add(Dense(units=self.output_dim, activation='sigmoid'))\n",
    "\n",
    "        # Compile the model with the specified learning rate\n",
    "        model.compile(\n",
    "            loss='binary_crossentropy',\n",
    "            optimizer=tf.keras.optimizers.get(hp.get('optimizer')),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        self.model = model  # Store the model in the attribute\n",
    "        return model\n",
    "\n",
    "    def tune_hyperparameters(self, X_train, y_train, epochs, batch_size, validation_data=None):\n",
    "        tuner = RandomSearch(\n",
    "            self.build_model,\n",
    "            objective='val_accuracy',\n",
    "            max_trials=10,  # Number of hyperparameter combinations to try\n",
    "            directory='keras_tuner_dir',  # Directory to store the results\n",
    "            project_name='simple_neural_network'\n",
    "        )\n",
    "\n",
    "        tuner.search(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=validation_data)\n",
    "\n",
    "        # Get the best model and its hyperparameters\n",
    "        best_model = tuner.get_best_models(num_models=1)[0]\n",
    "        best_hyperparameters = tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values\n",
    "\n",
    "        self.model = best_model\n",
    "        return best_hyperparameters\n",
    "\n",
    "    \n",
    "        \n",
    "    # Other methods remain unchanged\n",
    "    # def train(self, X_train, y_train, epochs, batch_size, validation_data=None):\n",
    "    #     class_weights = {0:8, 1:3}  # Adjust class weights based on your data distribution\n",
    "    #     self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=validation_data, class_weight=class_weights)\n",
    "    def train(self, X_train, y_train, epochs, batch_size, validation_data=None):\n",
    "        self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=validation_data)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        loss, accuracy = self.model.evaluate(X_test, y_test)\n",
    "        print(f'Test Loss: {loss:.4f}')\n",
    "        print(f'Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    def predict(self, X_data, threshold=0.5):\n",
    "        predictions_proba = self.model.predict(X_data)\n",
    "        predictions = (predictions_proba > threshold).astype(int)\n",
    "        return predictions\n",
    "\n",
    "# Usage\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = 1\n",
    "\n",
    "# Instantiate SimpleNeuralNetwork with input_dim and output_dim\n",
    "simple_nn = SimpleNeuralNetwork(input_dim, output_dim)\n",
    "\n",
    "# Get the hyperparameters dictionary\n",
    "hyperparameters = {'num_hidden_layers': 2,\n",
    "                   'units_0': 128,\n",
    "                   'activation_0': 'relu',\n",
    "                   'kernel_initializer_0': 'he_normal',\n",
    "                   'kernel_regularizer_0': None,\n",
    "                   'batch_normalization_0': True,\n",
    "                   'dropout_0': 0.3,\n",
    "                   'units_1': 64,\n",
    "                   'activation_1': 'relu',\n",
    "                   'kernel_initializer_1': 'glorot_uniform',\n",
    "                   'kernel_regularizer_1': 'l2',\n",
    "                   'batch_normalization_1': False,\n",
    "                   'dropout_1': 0.2,\n",
    "                   'optimizer': 'adam',\n",
    "                   'learning_rate': 0.0001}\n",
    "\n",
    "# Build and train the model using the provided hyperparameters\n",
    "model = simple_nn.build_model(hyperparameters)\n",
    "simple_nn.train(train_features, train_labels, epochs=10, batch_size=8192)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\suyash\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\suyash\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "22/22 [==============================] - 2s 8ms/step - loss: 104.4791 - accuracy: 0.5000\n",
      "Epoch 2/3\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 69.5368 - accuracy: 0.5000\n",
      "Epoch 3/3\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 34.7981 - accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "simple_nn.train(train_features, train_labels, epochs=3, batch_size=8192)\n",
    "# epochs and batch size are hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 24)]                 0         []                            \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 74)                   1850      ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 1)                    25        ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 116)                  8700      ['dense_11[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 117)                  0         ['dense_10[0][0]',            \n",
      " )                                                                   'dense_12[0][0]']            \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (None, 1)                    118       ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10693 (41.77 KB)\n",
      "Trainable params: 10693 (41.77 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "num_features=24\n",
    "# Define hyperparameters\n",
    "num_hidden_layers = 2\n",
    "units = [74, 116, 118]\n",
    "activations = ['relu', 'relu', 'tanh']\n",
    "# activations = ['relu', 'relu', 'relu']\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# Input layer\n",
    "input_layer = Input(shape=(num_features,))\n",
    "\n",
    "# Define wide branch\n",
    "wide_branch = Dense(1)(input_layer)\n",
    "\n",
    "# Define deep branch\n",
    "deep_branch = input_layer\n",
    "for i in range(num_hidden_layers):\n",
    "    deep_branch = Dense(units[i], activation=activations[i])(deep_branch)\n",
    "\n",
    "# Concatenate branches\n",
    "merged = concatenate([wide_branch, deep_branch])\n",
    "\n",
    "# Output layer\n",
    "output_layer = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# Create the model\n",
    "model1 = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "model1.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.4721 - accuracy: 0.7734\n",
      "Epoch 2/20\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.4691 - accuracy: 0.7751\n",
      "Epoch 3/20\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.4692 - accuracy: 0.7749\n",
      "Epoch 4/20\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.4683 - accuracy: 0.7750\n",
      "Epoch 5/20\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.4796 - accuracy: 0.7696\n",
      "Epoch 6/20\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.4763 - accuracy: 0.7709\n",
      "Epoch 7/20\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.4753 - accuracy: 0.7715\n",
      "Epoch 8/20\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.4668 - accuracy: 0.7764\n",
      "Epoch 9/20\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.4684 - accuracy: 0.7752\n",
      "Epoch 10/20\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.4707 - accuracy: 0.7741\n",
      "Epoch 11/20\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.4668 - accuracy: 0.7762\n",
      "Epoch 12/20\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.4722 - accuracy: 0.7736\n",
      "Epoch 13/20\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.4680 - accuracy: 0.7759\n",
      "Epoch 14/20\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.4669 - accuracy: 0.7762\n",
      "Epoch 15/20\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.4714 - accuracy: 0.7738\n",
      "Epoch 16/20\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.4727 - accuracy: 0.7728\n",
      "Epoch 17/20\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.4697 - accuracy: 0.7749\n",
      "Epoch 18/20\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.4728 - accuracy: 0.7730\n",
      "Epoch 19/20\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.4750 - accuracy: 0.7721\n",
      "Epoch 20/20\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.4714 - accuracy: 0.7746\n",
      "889/889 [==============================] - 2s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 20\n",
    "batch_size = 4096\n",
    "\n",
    "model1.fit(train_features, train_labels, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "# test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "# print(f'Test Loss: {test_loss:.4f}')\n",
    "# print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions_proba1 = pd.DataFrame(model1.predict(test_features))\n",
    "predictions_proba1.head()\n",
    "predictions = (predictions_proba1 > 0.65).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make predictions on test data\n",
    "# threshold = 0.65\n",
    "# # threshold = 0.65 gives best result\n",
    "# predictions = simple_nn.predict(test_features, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100721</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30234</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28624</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31173</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>573</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  Task\n",
       "0  100721     1\n",
       "1   30234     0\n",
       "2   28624     0\n",
       "3   31173     1\n",
       "4     573     0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# writing predictions to submission.csv\n",
    "fin_sub = pd.read_csv(\"./sample_submissions.csv\")\n",
    "fin_sub[\"Task\"] = predictions\n",
    "fin_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_sub.to_csv('./submission_NN.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
